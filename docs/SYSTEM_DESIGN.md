# System Design Approach

## ğŸ¯ Design Philosophy

This document explains the **architectural decisions**, **design patterns**, and **scalability considerations** behind the Knovator Job Importer system.

## ğŸ—ï¸ High-Level Architecture

### System Type
**Event-Driven Microservices Architecture**

### Core Principles
1. **Separation of Concerns**: Each component has a single responsibility
2. **Loose Coupling**: Components communicate via queue, not direct calls
3. **High Cohesion**: Related functionality grouped together
4. **Scalability First**: Designed to handle 1M+ jobs
5. **Fault Tolerance**: Graceful degradation on failures

## ğŸ“ Architecture Patterns

### 1. Producer-Consumer Pattern

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer   â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚    Queue     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   Consumer   â”‚
â”‚  (Fetcher)   â”‚       â”‚   (Redis)    â”‚       â”‚   (Worker)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why?**
- âœ… Decouples fetching from processing
- âœ… Allows different scaling for producer/consumer
- âœ… Built-in backpressure handling
- âœ… Survives temporary failures

**Implementation**:
- Producer: `FetcherService` + `QueueService`
- Queue: Redis + BullMQ
- Consumer: Worker process

### 2. Batch Processing Pattern

```
Jobs arrive â†’ Buffer by source â†’ Batch (100) â†’ Bulk write â†’ MongoDB
```

**Why?**
- âœ… 10x faster than individual operations
- âœ… Reduces network round trips
- âœ… Optimizes MongoDB connection usage
- âœ… Lower CPU overhead

**Implementation**:
```typescript
// Buffer accumulation
buffer.get(source).push(job);

// Batch creation
const chunk = items.splice(0, BATCH_SIZE);

// Bulk operation
await JobModel.bulkWrite(ops, { ordered: false });
```

### 3. Repository Pattern

```
Controller â†’ Service â†’ Repository (Model) â†’ Database
```

**Why?**
- âœ… Separates business logic from data access
- âœ… Easy to test (mock repository)
- âœ… Can swap database without changing business logic
- âœ… Centralized data validation

**Implementation**:
- Repository: Mongoose models
- Service: Business logic layer
- Controller: HTTP request handling

### 4. Dead Letter Queue (DLQ) Pattern

```
Job fails â†’ Retry 3x â†’ Move to DLQ â†’ Manual intervention
```

**Why?**
- âœ… Prevents poison messages from blocking queue
- âœ… Allows debugging failed jobs
- âœ… Can requeue after fixing root cause
- âœ… Maintains system health

**Implementation**:
```typescript
if (job.attemptsMade >= maxAttempts) {
  await dlqQueue.add({ jobData, reason: error });
}
```

## ğŸ¨ Design Decisions

### Decision 1: Why BullMQ over Bull?

| Feature | Bull | BullMQ |
|---------|------|--------|
| TypeScript | Partial | Native |
| Performance | Good | Better (2x) |
| Redis Cluster | Limited | Full support |
| Maintenance | Slow | Active |
| API | Callback-based | Promise-based |

**Verdict**: BullMQ âœ…

### Decision 2: Why Batch Processing?

**Without Batching** (1000 jobs):
```
Time: ~10 seconds
Operations: 1000 MongoDB calls
Network: 1000 round trips
```

**With Batching** (1000 jobs, batch size 100):
```
Time: ~1 second
Operations: 10 MongoDB calls
Network: 10 round trips
```

**Performance Gain**: 10x faster âœ…

### Decision 3: Why `ordered: false` in bulkWrite?

**ordered: true**:
```typescript
ops = [op1, op2_FAIL, op3, op4];
// Result: op1 succeeds, op2 fails, op3 & op4 SKIPPED
// Lost: 2 operations
```

**ordered: false**:
```typescript
ops = [op1, op2_FAIL, op3, op4];
// Result: op1, op3, op4 succeed, op2 fails
// Lost: 0 operations (partial failure OK)
```

**Verdict**: `ordered: false` âœ…

### Decision 4: Why Separate import_logs Collection?

**Alternative**: Embed stats in jobs collection
```typescript
// âŒ BAD
{
  source: "feed1",
  jobs: [...],
  stats: { new: 10, updated: 5 }
}
```

**Current**: Separate collection
```typescript
// âœ… GOOD
// jobs: Just job data
// import_logs: Just import stats
```

**Benefits**:
- âœ… Cleaner schema
- âœ… Faster queries (indexed separately)
- âœ… Can delete old logs without affecting jobs
- âœ… Different retention policies

### Decision 5: Why Deterministic Job IDs?

```typescript
jobId = `${source}#${guid}`;
// Example: "https://jobicy.com/?feed=job_feed#12345"
```

**Benefits**:
- âœ… BullMQ automatically deduplicates
- âœ… Prevents same job enqueued twice
- âœ… Idempotent (safe to retry)
- âœ… No need for separate dedup logic

### Decision 6: Why NestJS over Express?

| Feature | Express | NestJS |
|---------|---------|--------|
| Structure | Manual | Built-in (modules) |
| DI | Manual | Native |
| TypeScript | Add-on | Native |
| Testing | Manual setup | Built-in |
| Validation | Manual | Decorators |
| Schedule | Add library | Built-in |

**Verdict**: NestJS âœ… (Better for scalable systems)

## ğŸ”„ Data Flow Design

### 1. Async by Default

```
User Request â†’ Immediate Response (202 Accepted)
              â†“
         Queue (background)
              â†“
         Worker (async)
              â†“
         Results (poll/view later)
```

**Why?**
- âœ… User doesn't wait for slow operations
- âœ… Better UX (instant feedback)
- âœ… System can handle spikes
- âœ… Resilient to failures

### 2. Stateless Components

```
Server instance 1 â”€â”
Server instance 2 â”€â”¼â”€â†’ Shared Redis â†â”€â”¬â”€ Worker instance 1
Server instance N â”€â”˜                   â”œâ”€ Worker instance 2
                                       â””â”€ Worker instance N
```

**Why?**
- âœ… Horizontal scaling (add instances)
- âœ… No session affinity needed
- âœ… Load balancer friendly
- âœ… High availability

### 3. Event Sourcing (Logs)

```
Every import â†’ Log entry â†’ Historical record
```

**Benefits**:
- âœ… Audit trail
- âœ… Analytics over time
- âœ… Debug issues
- âœ… Track trends

## ğŸ“Š Scalability Strategy

### Vertical Scaling (Single Machine)

```
1. Increase Worker Concurrency
   WORKER_CONCURRENCY=10 â†’ 20
   
2. Increase Batch Size
   WORKER_BATCH_SIZE=100 â†’ 500
   
3. Optimize Flush Interval
   WORKER_FLUSH_MS=3000 â†’ 5000
```

**Limits**: CPU, RAM, Network

### Horizontal Scaling (Multiple Machines)

```
1. Add More Workers
   docker-compose up --scale worker=10
   
2. Add More Servers (API)
   Load balancer â†’ [Server1, Server2, ..., ServerN]
   
3. Database Sharding (MongoDB)
   Shard by: source OR company
```

**No Limits**: Linear scaling

### Current Capacity vs Target

| Metric | Current (1 Worker) | Target (10 Workers) |
|--------|-------------------|---------------------|
| Jobs/sec | 500-1000 | 5000-10000 |
| Daily capacity | 43M-86M | 430M-860M |
| Batch size | 100 | 500 |
| Concurrency | 10 | 20 |

## ğŸ›¡ï¸ Reliability Design

### 1. Retry Strategy

```
Transient Error â†’ Retry with backoff â†’ Success/DLQ
```

**Configuration**:
- Attempts: 3
- Backoff: Exponential (1s, 2s, 4s)
- Max delay: Configurable

### 2. Circuit Breaker (Future)

```
Failures > threshold â†’ Open circuit â†’ Fast fail â†’ Health check â†’ Close
```

### 3. Graceful Degradation

```
Feed fails â†’ Log error â†’ Continue other feeds â†’ Partial success
```

### 4. Health Checks

```
GET /jobs/health â†’ Check DB, Redis, Queue â†’ Return status
```

## ğŸ” Security Considerations

### 1. Input Validation

```typescript
@IsUrl()
@IsNotEmpty()
url: string;  // DTOs validate all inputs
```

### 2. Rate Limiting

```typescript
limiter: {
  max: 100,      // Max requests
  duration: 1000 // per second
}
```

### 3. Environment Separation

```
.env.development
.env.production
.env.test
```

### 4. Secrets Management

```env
# Never commit secrets
MONGO_URI=mongodb+srv://...
REDIS_URL=redis://:password@...

# Use env variables or secret managers
```

## ğŸ“ˆ Performance Optimizations

### 1. Database Indexing

```typescript
// Compound unique index
JobSchema.index({ source: 1, guid: 1 }, { unique: true });

// Query optimization
ImportLogSchema.index({ createdAt: -1 });
```

### 2. Connection Pooling

```typescript
// Reuse connections
const connection = new IORedis(REDIS_URL);
const queue1 = new Queue('q1', { connection });
const queue2 = new Queue('q2', { connection });
```

### 3. Batch Operations

```typescript
// Instead of N operations
for (const item of items) {
  await collection.insert(item);
}

// One operation
await collection.bulkWrite(items);
```

### 4. Selective Field Loading

```typescript
// Load only needed fields
const logs = await ImportLog.find()
  .select('fileName totalFetched createdAt')
  .lean();  // Convert to plain objects (faster)
```

## ğŸ¯ Design Trade-offs

### Trade-off 1: Consistency vs Availability

**Choice**: Eventual consistency
- Queue â†’ Process later
- Accept brief inconsistency
- Gain: High availability

### Trade-off 2: Complexity vs Scalability

**Choice**: More complex architecture
- Multiple components (server, worker, queue)
- Gain: Can scale to millions of jobs

### Trade-off 3: Storage vs Performance

**Choice**: Denormalize some data
- Store computed values (totalImported)
- Gain: Faster queries
- Cost: More storage

### Trade-off 4: Real-time vs Throughput

**Choice**: Near real-time (buffered)
- Batch every 3 seconds
- Gain: 10x throughput
- Cost: 3-second delay

## ğŸ“š Design Patterns Used

1. âœ… **Producer-Consumer**: Fetcher â†’ Queue â†’ Worker
2. âœ… **Repository**: Models abstract database
3. âœ… **Service Layer**: Business logic separation
4. âœ… **Factory**: Queue creation
5. âœ… **Singleton**: Shared connections
6. âœ… **Strategy**: Different feed parsers (RSS, Atom)
7. âœ… **Observer**: Event handlers (worker.on)
8. âœ… **Batch Processing**: Bulk operations
9. âœ… **Circuit Breaker**: (Future) Failure handling
10. âœ… **CQRS**: (Partial) Separate reads/writes

## ğŸ“ Lessons Learned

### What Worked Well

1. âœ… **Queue-based architecture**: Easy scaling
2. âœ… **Batch processing**: Massive performance gain
3. âœ… **TypeScript**: Caught bugs early
4. âœ… **NestJS modules**: Clean code organization
5. âœ… **Separate import logs**: Clear history tracking

### What Could Be Improved

1. ğŸ”„ **Streaming XML parser**: For very large feeds
2. ğŸ”„ **Circuit breaker**: Better failure isolation
3. ğŸ”„ **Distributed tracing**: Cross-service debugging
4. ğŸ”„ **Schema validation**: Strict data contracts
5. ğŸ”„ **GraphQL API**: More flexible queries

## ğŸš€ Future Enhancements

1. **Real-time Updates**: WebSockets for live import status
2. **ML-based Deduplication**: Smart duplicate detection
3. **Multi-tenancy**: Support multiple organizations
4. **Analytics Dashboard**: Visualize import trends
5. **Auto-scaling**: Based on queue size
6. **Geo-distribution**: Multiple regions
7. **A/B Testing**: Different import strategies

## âœ… Summary

The system design achieves:
- âœ… **Scalability**: 1M+ jobs capability
- âœ… **Reliability**: Retry + DLQ
- âœ… **Maintainability**: Clean architecture
- âœ… **Performance**: Batch processing
- âœ… **Observability**: Logging + metrics
- âœ… **Testability**: Modular design

---

**Designed by**: Knovator Job Importer Team  
**Last Updated**: January 2026
